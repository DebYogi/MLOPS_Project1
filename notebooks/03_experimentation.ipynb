{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcd29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "from contextlib import nullcontext\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814c1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "mlflow_tracking_uri = 'http://localhost:5555'  # Optional: e.g., 'http://localhost:5555'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfa7aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted DataFrame:\n",
      "      price  sqft  bedrooms  bathrooms  location  year_built  condition  \\\n",
      "0    495000  1527         2        1.5       2.0        1956        1.0   \n",
      "1    752000  2526         3        2.5       0.0        1998        2.0   \n",
      "2    319000  1622         2        1.5       1.0        1975        0.0   \n",
      "3   1210000  3102         4        3.0       4.0        2005        2.0   \n",
      "4    462000  1835         2        2.0       3.0        1982        1.0   \n",
      "..      ...   ...       ...        ...       ...         ...        ...   \n",
      "79   530000  2080         3        2.0       3.0        1991        1.0   \n",
      "80   372000  1640         2        1.5       2.0        1963        0.0   \n",
      "81   592000  2220         3        2.0       0.0        1985        1.0   \n",
      "82   328000  1730         2        1.5       1.0        1965        0.0   \n",
      "83  1190000  3170         4        3.5       4.0        2006        2.0   \n",
      "\n",
      "    house_age  price_per_sqft  bed_bath_ratio  \n",
      "0          69      324.165029        1.333333  \n",
      "1          27      297.703880        1.200000  \n",
      "2          50      196.670777        1.333333  \n",
      "3          20      390.070922        1.333333  \n",
      "4          43      251.771117        1.000000  \n",
      "..        ...             ...             ...  \n",
      "79         34      254.807692        1.500000  \n",
      "80         62      226.829268        1.333333  \n",
      "81         40      266.666667        1.500000  \n",
      "82         60      189.595376        1.333333  \n",
      "83         19      375.394322        1.142857  \n",
      "\n",
      "[84 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = '../data/processed/data_scientists_features.csv'  # Update path if needed\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "import pandas as pd\n",
    "# Sample data\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define encoding maps\n",
    "location_map = {\n",
    "    'Downtown': 0,\n",
    "    'Rural': 1,\n",
    "    'Suburb': 2,\n",
    "    'Urban': 3,\n",
    "    'Waterfront': 4\n",
    "}\n",
    "\n",
    "condition_map = {\n",
    "    'Fair': 0,\n",
    "    'Good': 1,\n",
    "    'Excellent': 2\n",
    "}\n",
    "\n",
    "# Apply mappings\n",
    "df['location'] = df['location'].map(location_map)\n",
    "df['condition'] = df['condition'].map(condition_map)\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(\"‚úÖ Converted DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6b19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('price', axis=1)\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"‚úÖ Data split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea62c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Top 10 Selected Features by RFE:\n",
      " - sqft\n",
      " - bedrooms\n",
      " - bathrooms\n",
      " - location\n",
      " - year_built\n",
      " - condition\n",
      " - house_age\n",
      " - price_per_sqft\n",
      " - bed_bath_ratio\n",
      "\n",
      "‚ùå Features Ignored by RFE:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Use XGBoost for RFE to stay consistent\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# RFE\n",
    "rfe_selector = RFE(estimator=xgb_model, n_features_to_select=10)\n",
    "rfe_selector.fit(X_train, y_train)\n",
    "rfe_selected_features = X.columns[rfe_selector.support_]\n",
    "rfe_ignored_features = X.columns[~rfe_selector.support_]\n",
    "\n",
    "print(\"‚úÖ Top 10 Selected Features by RFE:\")\n",
    "for feature in rfe_selected_features:\n",
    "    print(f\" - {feature}\")\n",
    "\n",
    "print(\"\\n‚ùå Features Ignored by RFE:\")\n",
    "for feature in rfe_ignored_features:\n",
    "    print(f\" - {feature}\")\n",
    "\n",
    "# Store for config\n",
    "selected_features_dict = {\n",
    "    'rfe': list(rfe_selected_features)\n",
    "}\n",
    "\n",
    "# Filter datasets to use only selected features for experimentation\n",
    "X_train = X_train[rfe_selected_features]\n",
    "X_test = X_test[rfe_selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056abaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 19:30:39 INFO mlflow.tracking.fluent: Experiment with name 'House Price Prediction Experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Optional MLflow setup\n",
    "if mlflow_tracking_uri:\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(\"House Price Prediction Experiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96df1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'GradientBoosting': GradientBoostingRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor(objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "model_grids = {\n",
    "    'LinearRegression': {},\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [100, 150],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 250],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 10]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 150],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 10]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5544f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: http://localhost:5555\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_with_gridsearch(name, model, grid, X_train, y_train, X_test, y_test):\n",
    "    if grid:\n",
    "        clf = GridSearchCV(model, grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        best_model = clf.best_estimator_\n",
    "        best_params = clf.best_params_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        best_model = model\n",
    "        best_params = model.get_params()\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'model': best_model,\n",
    "        'params': best_params\n",
    "    }\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow_tracking_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff2ddc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training LinearRegression...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=name, nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m mlflow_tracking_uri \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     evaluation = \u001b[43mevaluate_model_with_gridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     results[name] = evaluation\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mlflow_tracking_uri:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mevaluate_model_with_gridsearch\u001b[39m\u001b[34m(name, model, grid, X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m      6\u001b[39m     best_params = clf.best_params_\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     best_model = model\n\u001b[32m     10\u001b[39m     best_params = model.get_params()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MLOPS_PACKT/hosue-price-predictor/.venv/lib/python3.11/site-packages/sklearn/linear_model/_base.py:648\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    644\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    646\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m sample_weight = _check_sample_weight(\n\u001b[32m    653\u001b[39m     sample_weight, X, dtype=X.dtype, only_non_negative=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    654\u001b[39m )\n\u001b[32m    656\u001b[39m X, y, X_offset, y_offset, X_scale = _preprocess_data(\n\u001b[32m    657\u001b[39m     X,\n\u001b[32m    658\u001b[39m     y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    661\u001b[39m     sample_weight=sample_weight,\n\u001b[32m    662\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MLOPS_PACKT/hosue-price-predictor/.venv/lib/python3.11/site-packages/sklearn/base.py:584\u001b[39m, in \u001b[36mBaseEstimator._validate_data\u001b[39m\u001b[34m(self, X, y, reset, validate_separately, **check_params)\u001b[39m\n\u001b[32m    582\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m    583\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m     out = X, y\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MLOPS_PACKT/hosue-price-predictor/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1106\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1101\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1103\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1122\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1124\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MLOPS_PACKT/hosue-price-predictor/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m    915\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    916\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    917\u001b[39m             % (array.ndim, estimator_name)\n\u001b[32m    918\u001b[39m         )\n\u001b[32m    920\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples > \u001b[32m0\u001b[39m:\n\u001b[32m    929\u001b[39m     n_samples = _num_samples(array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/MLOPS_PACKT/hosue-price-predictor/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    146\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    147\u001b[39m     msg_err += (\n\u001b[32m    148\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_comparison\") if mlflow_tracking_uri else nullcontext():\n",
    "    for name, model in models.items():\n",
    "        logger.info(f\"Training {name}...\")\n",
    "        with mlflow.start_run(run_name=name, nested=True) if mlflow_tracking_uri else nullcontext():\n",
    "            evaluation = evaluate_model_with_gridsearch(name, model, model_grids[name], X_train, y_train, X_test, y_test)\n",
    "            results[name] = evaluation\n",
    "\n",
    "            if mlflow_tracking_uri:\n",
    "                mlflow.log_params(evaluation['params'])\n",
    "                mlflow.log_metrics({\n",
    "                    'mae': evaluation['mae'],\n",
    "                    'mse': evaluation['mse'],\n",
    "                    'rmse': evaluation['rmse'],\n",
    "                    'r2': evaluation['r2']\n",
    "                })\n",
    "                mlflow.sklearn.log_model(evaluation['model'], artifact_path=name.lower().replace(\" \", \"_\"))\n",
    "            \n",
    "            print(f\"{name} R2: {evaluation['r2']:.4f}, RMSE: {evaluation['rmse']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_metrics(results, metric='r2'):\n",
    "    names = list(results.keys())\n",
    "    values = [results[name][metric] for name in names]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(names, values)\n",
    "    plt.title(f'Model Comparison by {metric.upper()}')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_model_metrics(results, metric='r2')\n",
    "plot_model_metrics(results, metric='rmse')\n",
    "plot_model_metrics(results, metric='mae')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Save model config with selected features \n",
    "# Display information about the best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['r2'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_params = best_model.get_params()\n",
    "best_r2 = float(results[best_model_name]['r2'])\n",
    "best_mae = float(results[best_model_name]['mae'])\n",
    "best_rmse = float(results[best_model_name]['rmse'])\n",
    "\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
    "print(f\"   MAE: {best_mae:.2f}\")\n",
    "print(f\"   RMSE: {best_rmse:.2f}\")\n",
    "\n",
    "model_config = {\n",
    "    'model': {\n",
    "        'name': 'house_price_model',\n",
    "        'best_model': best_model_name,\n",
    "        'parameters': best_params,\n",
    "        'r2_score': best_r2,\n",
    "        'mae': best_mae,\n",
    "        'target_variable': 'price',\n",
    "        'feature_sets': selected_features_dict\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = '../configs/model_config.yaml'\n",
    "os.makedirs(os.path.dirname(config_path), exist_ok=True)\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(model_config, f)\n",
    "\n",
    "print(f\"Saved model config to {config_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hosue-price-predictor (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
